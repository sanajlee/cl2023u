---
layout: default
---


### Course Information

* Instructor: Sangah Lee (sanalee@snu.ac.kr)
* TA: Minji Kang (mnjkng@snu.ac.kr)

This course outlines the fundamental notions and theories on computational linguistics and natural language processing, dealing with current issues on deep learning models and the Transformer mechanism and large-scale language models based on them.

* Prerequisite course: Language and Computer (or, students that can implement at least the logistic regression model in Python are allowed)
* Students majoring in engineering could get separate grades.

### Resources
* [Numpy and Data Representation](https://jalammar.github.io/visual-numpy/)
* [NLTK (Natural Language Toolkit)](https://www.nltk.org/)
* [SpaCy](https://spacy.io/)
* [textacy](https://textacy.readthedocs.io/en/latest/)
* [csv](https://docs.python.org/3/library/csv.html)
* [json](https://docs.python.org/3/library/json.html)
* [Python "Class"](https://docs.python.org/3/tutorial/classes.html)


### Syllabus

* **Week 0 (3/2 Thu)** Course Introduction
  * slides: ![download](https://github.com/sanajlee/cl2023u/raw/main/cl0_courseintro.pdf)

* **Week 1 (3/7, 3/9)** Basics of Text Processing
  * [Natural Language Processing is Fun!](https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e)
  * [Natural Langauge Processing with Python](https://www.nltk.org/book/)
  * [Hands-on-nltk-tutorial](https://github.com/hb20007/hands-on-nltk-tutorial)
  * PyTorch
    * [Matrices](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_matrices/)
    * [Gradients](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_gradients/)
    * [Linear Regression](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_linear_regression/)
    * [Logistic Regression](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_logistic_regression/)
  
* **Week 2 (3/14, 3/16)** PyTorch: Feed Forward Neural Network, Recurrent Neural Networks
  * [Feed Forward Neural Network (FFN)](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/)
  * [Recurrent Neural Network (RNN)](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork/)

* **Week 3 (3/21, 3/23)** PyTorch: Convolutional Neural Networks, Long Short Term Neural Network (LSTM)
  * [Convolutional Neural Network (CNN)](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_convolutional_neuralnetwork/)
  * [Long Short-Term Memory (LSTM)](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_lstm_neuralnetwork/)

* **Week 4 (3/28, 3/30)** Language Model I: Statistical Language Model (N-gram)

* **Week 5 (4/4, 4/6)** N-gram and Entropy

* **Week 6 (4/11, 4/13)** Text Classification

* **Week 7 (4/18, 4/20)** Language Model II: Word Embedding

* **Week 8 (4/25, 4/27)** Midterm Exam

* **Week 9 (5/2, 5/4)** Sequence-to-Sequence Model (Encoder-Decoder)

* **Week 10 (5/9, 5/11)** Attention

* **Week 11 (5/16, 5/18)** Transformer

* **Week 12 (5/23, 5/25)** Transformer-based Pre-trained Models

* **Week 13 (5/30, 6/1)** HuggingFace Transformer

* **Week 14 (6/8 Thu, 6/13 Tue)** Various NLP Tasks based on Transformer

* **Week 15 (6/15 Thu)** Final Project Presentations






